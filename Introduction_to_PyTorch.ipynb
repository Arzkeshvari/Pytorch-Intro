{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to PyTorch [howsam.org].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRtLcav47WzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whWQnn77nUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.random.rand(100, 1)\n",
        "y = 1 + 2 * x + 0.1 * np.random.randn(100, 1)\n",
        "\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuklErXr8lhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_idx = idx[:80]\n",
        "val_idx = idx[80:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuAOOQ1M8sn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO0T62Xf8MTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x_train, y_train, 'o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR61wB969Gsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x_val, y_val, 'o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLml3PGj9SvT",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq9W6wFk9UVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70828132-bc8f-4356-8086-e0ea7978a095"
      },
      "source": [
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "print(a, b)\n",
        "yp = a + b * x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.5883935] [-0.16623771]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT4BdBS6-Fo6",
        "colab_type": "text"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WxMgqCM-FOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d689c1dc-10a0-44b4-8bee-b87df125b9fb"
      },
      "source": [
        "error = (yp - y_train)\n",
        "loss = (error ** 2).mean()\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5323423090116217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2j80pVE-Cqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c4f16eb-ce94-476a-c5e3-f9dc37ae5e76"
      },
      "source": [
        "a_grad = -2 * error.mean()\n",
        "b_grad = -2 * (x_train * error).mean()\n",
        "print(a_grad, b_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8454856634375295 0.7133907178322277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkJ5MxXY-5Ef",
        "colab_type": "text"
      },
      "source": [
        "# Update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCddNoZl_HX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpIztZ0_-81e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f86558aa-22f3-4b41-9922-56a3b4ce6aab"
      },
      "source": [
        "a = a - lr * a_grad\n",
        "b = b - lr * b_grad\n",
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.38652447] [-0.21157466]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1fwMosD_mX3",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBWpt02o_l1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(2)\n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "print(a, b)\n",
        "\n",
        "lr = 0.001\n",
        "n_epochs = 100000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Model\n",
        "  yp = a + b * x_train\n",
        "\n",
        "  error = (y_train - yp)\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  a_grad = -2 * error.mean()\n",
        "  b_grad = -2 * (x_train * error).mean()\n",
        "\n",
        "  a = a - lr * a_grad\n",
        "  b = b - lr * b_grad\n",
        "  print(loss)\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9K1v_J3B9pu",
        "colab_type": "text"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5n0TwulB8sq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1fa14357-1aa9-40a0-9fe4-9656d30fd132"
      },
      "source": [
        "plt.plot(x_val, y_val, 'ro')\n",
        "\n",
        "yhat = a + b * x_val\n",
        "plt.plot(x_val, yhat, 'g')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f521c07e4e0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAw_hhj9CsUA",
        "colab_type": "text"
      },
      "source": [
        "# Torch 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn2A4ldKCygo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9c4WuuoD19f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.from_numpy(x_train)\n",
        "y_train = torch.from_numpy(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar0X_ytMCeXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.random.seed(2)\n",
        "# a = np.random.randn(1)\n",
        "# b = np.random.randn(1)\n",
        "\n",
        "torch.manual_seed(10)\n",
        "a = torch.randn(1)\n",
        "b = torch.randn(1)\n",
        "\n",
        "print(a, b)\n",
        "\n",
        "lr = 0.1\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Model\n",
        "  yp = a + b * x_train\n",
        "\n",
        "  error = (y_train - yp)\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  a_grad = -2 * error.mean()\n",
        "  b_grad = -2 * (x_train * error).mean()\n",
        "\n",
        "  a = a - lr * a_grad\n",
        "  b = b - lr * b_grad\n",
        "  print(loss)\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MkdLWkxEMH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = torch.from_numpy(x_val)\n",
        "y_val = torch.from_numpy(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9q6ON5hEGHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "43b47f4c-1a1e-4700-8604-3966f4db92d4"
      },
      "source": [
        "plt.plot(x_val, y_val, 'ro')\n",
        "\n",
        "yhat = a + b * x_val\n",
        "plt.plot(x_val.numpy(), yhat.numpy(), 'g')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f51d21e3240>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsHgPOyzFLQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRgzJobpFRU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b2211e3-7ce2-475c-a317-77597e47f648"
      },
      "source": [
        "x = torch.randn(1, requires_grad=True)\n",
        "# a = torch.randn(1)\n",
        "print(x)\n",
        "\n",
        "# dy/dx = 2 * x\n",
        "y = x ** 2\n",
        "\n",
        "y.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.9198], requires_grad=True)\n",
            "tensor([2.5383])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpf75SOBL-TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.float()\n",
        "y_train = y_train.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YOII9gaOGkxq",
        "colab": {}
      },
      "source": [
        "# np.random.seed(2)\n",
        "# a = np.random.randn(1)\n",
        "# b = np.random.randn(1)\n",
        "\n",
        "# torch.manual_seed(10)\n",
        "# a = torch.randn(1, requires_grad=True)\n",
        "# b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# print(a, b)\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(1, 1))\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "# lr = 0.1\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Model\n",
        "  # yp = a + b * x_train\n",
        "  yp = model(x_train)\n",
        "\n",
        "  l = loss(yp, y_train)\n",
        "  # error = (y_train - yp)\n",
        "  # loss = (error ** 2).mean()\n",
        "  l.backward()\n",
        "\n",
        "  # a_grad = -2 * error.mean()\n",
        "  # b_grad = -2 * (x_train * error).mean()\n",
        "\n",
        "  # a = a - lr * a.grad\n",
        "  # b = b - lr * b.grad\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  print(l.item())\n",
        "\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Um7CXkQpKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nYgQiEbENY6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a127d646-e83b-45c3-f6b9-19dc45ae9daf"
      },
      "source": [
        "# np.random.seed(2)\n",
        "# a = np.random.randn(1)\n",
        "# b = np.random.randn(1)\n",
        "\n",
        "# torch.manual_seed(10)\n",
        "# a = torch.randn(1, requires_grad=True)\n",
        "# b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# print(a, b)\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(1, 1))\n",
        "class LinearReg(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #\n",
        "    self.neuron = torch.nn.Linear(1, 1)\n",
        "    self.neuron2 = torch.nn.Linear(1, 1)\n",
        "    self.relu = torch.nn.Relu()\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = F.relu(self.neuron(x))\n",
        "    z = self.neuron2(y)\n",
        "    p = y + z\n",
        "    return p, y, z\n",
        "\n",
        "model = LinearReg()\n",
        "model.cpu()\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "# lr = 0.1\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Model\n",
        "  # yp = a + b * x_train\n",
        "  yp, yp2, yp3 = model(x_train)\n",
        "\n",
        "  l = loss(yp, y_train)\n",
        "  l2 = loss2(yp2, y_train)\n",
        "  l3 = loss3(yp3, y_train)\n",
        "  L = l + l2 + l3\n",
        "  # error = (y_train - yp)\n",
        "  # loss = (error ** 2).mean()\n",
        "  l.backward()\n",
        "\n",
        "  # a_grad = -2 * error.mean()\n",
        "  # b_grad = -2 * (x_train * error).mean()\n",
        "\n",
        "  # a = a - lr * a.grad\n",
        "  # b = b - lr * b.grad\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  print(l.item())\n",
        "\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.8386311531066895\n",
            "1.6388925313949585\n",
            "0.9586746096611023\n",
            "0.5727599263191223\n",
            "0.35357025265693665\n",
            "0.2288375198841095\n",
            "0.1576242446899414\n",
            "0.11674060672521591\n",
            "0.0930500254034996\n",
            "0.07911098003387451\n",
            "0.0707077905535698\n",
            "0.0654522031545639\n",
            "0.061990998685359955\n",
            "0.059557460248470306\n",
            "0.05771694704890251\n",
            "0.056223064661026\n",
            "0.054935913532972336\n",
            "0.053776077926158905\n",
            "0.0526982918381691\n",
            "0.051676712930202484\n",
            "0.050696443766355515\n",
            "0.049748849123716354\n",
            "0.0488288477063179\n",
            "0.047933291643857956\n",
            "0.04706024378538132\n",
            "0.046208396553993225\n",
            "0.04537680000066757\n",
            "0.044564731419086456\n",
            "0.043771617114543915\n",
            "0.04299690201878548\n",
            "0.04224015399813652\n",
            "0.04150090366601944\n",
            "0.040778737515211105\n",
            "0.040073249489068985\n",
            "0.03938406705856323\n",
            "0.038710806518793106\n",
            "0.038053080439567566\n",
            "0.03741054609417915\n",
            "0.03678283840417862\n",
            "0.036169640719890594\n",
            "0.03557058423757553\n",
            "0.03498537093400955\n",
            "0.03441367298364639\n",
            "0.03385516628623009\n",
            "0.03330954536795616\n",
            "0.03277655690908432\n",
            "0.03225585073232651\n",
            "0.03174716979265213\n",
            "0.031250230967998505\n",
            "0.030764764174818993\n",
            "0.03029051423072815\n",
            "0.02982720360159874\n",
            "0.02937459945678711\n",
            "0.028932446613907814\n",
            "0.028500491753220558\n",
            "0.02807852067053318\n",
            "0.02766628935933113\n",
            "0.027263570576906204\n",
            "0.02687014639377594\n",
            "0.026485824957489967\n",
            "0.026110369712114334\n",
            "0.025743579491972923\n",
            "0.025385256856679916\n",
            "0.025035211816430092\n",
            "0.024693245068192482\n",
            "0.02435917779803276\n",
            "0.024032823741436005\n",
            "0.023714007809758186\n",
            "0.023402545601129532\n",
            "0.023098280653357506\n",
            "0.022801043465733528\n",
            "0.022510666400194168\n",
            "0.022226985543966293\n",
            "0.02194986864924431\n",
            "0.021679136902093887\n",
            "0.021414658054709435\n",
            "0.02115628868341446\n",
            "0.020903881639242172\n",
            "0.020657306537032127\n",
            "0.020416423678398132\n",
            "0.02018110081553459\n",
            "0.019951213151216507\n",
            "0.01972663588821888\n",
            "0.019507242366671562\n",
            "0.019292915239930153\n",
            "0.019083533436059952\n",
            "0.018878988921642303\n",
            "0.018679173663258553\n",
            "0.018483959138393402\n",
            "0.018293257802724838\n",
            "0.018106959760189056\n",
            "0.0179249569773674\n",
            "0.017747163772583008\n",
            "0.01757347211241722\n",
            "0.017403794452548027\n",
            "0.017238043248653412\n",
            "0.017076101154088974\n",
            "0.01691790297627449\n",
            "0.016763361170887947\n",
            "0.016612384468317032\n",
            "0.016464903950691223\n",
            "0.016320813447237015\n",
            "0.01618006080389023\n",
            "0.016042549163103104\n",
            "0.015908222645521164\n",
            "0.01577698066830635\n",
            "0.015648778527975082\n",
            "0.015523536130785942\n",
            "0.015401192009449005\n",
            "0.015281669795513153\n",
            "0.015164902433753014\n",
            "0.01505083404481411\n",
            "0.01493939757347107\n",
            "0.014830537140369415\n",
            "0.014724182896316051\n",
            "0.014620296657085419\n",
            "0.014518795534968376\n",
            "0.014419649727642536\n",
            "0.014322792179882526\n",
            "0.014228159561753273\n",
            "0.014135723933577538\n",
            "0.014045419171452522\n",
            "0.013957197777926922\n",
            "0.013871016912162304\n",
            "0.013786819763481617\n",
            "0.013704565353691578\n",
            "0.013624219223856926\n",
            "0.013545721769332886\n",
            "0.013469040393829346\n",
            "0.01339412946254015\n",
            "0.01332094520330429\n",
            "0.013249454088509083\n",
            "0.013179605826735497\n",
            "0.01311137992888689\n",
            "0.01304472703486681\n",
            "0.012979608960449696\n",
            "0.012915996834635735\n",
            "0.012853856198489666\n",
            "0.012793144211173058\n",
            "0.012733842246234417\n",
            "0.012675901874899864\n",
            "0.012619301676750183\n",
            "0.012564010918140411\n",
            "0.012509994208812714\n",
            "0.012457224540412426\n",
            "0.012405673041939735\n",
            "0.012355315499007702\n",
            "0.012306119315326214\n",
            "0.012258058413863182\n",
            "0.012211108580231667\n",
            "0.012165239080786705\n",
            "0.012120427563786507\n",
            "0.012076650746166706\n",
            "0.012033890932798386\n",
            "0.011992107145488262\n",
            "0.011951303109526634\n",
            "0.011911430396139622\n",
            "0.011872481554746628\n",
            "0.011834429576992989\n",
            "0.01179725956171751\n",
            "0.011760945431888103\n",
            "0.011725472286343575\n",
            "0.011690816842019558\n",
            "0.011656965129077435\n",
            "0.011623886413872242\n",
            "0.011591577902436256\n",
            "0.011560017243027687\n",
            "0.011529183015227318\n",
            "0.011499056592583656\n",
            "0.011469634249806404\n",
            "0.011440882459282875\n",
            "0.01141279749572277\n",
            "0.011385361663997173\n",
            "0.011358557268977165\n",
            "0.011332375928759575\n",
            "0.011306796222925186\n",
            "0.011281806044280529\n",
            "0.011257399804890156\n",
            "0.011233550496399403\n",
            "0.011210254393517971\n",
            "0.011187496595084667\n",
            "0.011165261268615723\n",
            "0.011143537238240242\n",
            "0.011122319847345352\n",
            "0.011101586744189262\n",
            "0.011081341654062271\n",
            "0.01106155663728714\n",
            "0.011042232625186443\n",
            "0.011023348197340965\n",
            "0.011004905216395855\n",
            "0.010986887849867344\n",
            "0.01096928771585226\n",
            "0.010952090844511986\n",
            "0.010935293510556221\n",
            "0.010918879881501198\n",
            "0.010902849026024342\n",
            "0.010887190699577332\n",
            "0.01087188720703125\n",
            "0.01085694134235382\n",
            "0.010842337273061275\n",
            "0.010828069411218166\n",
            "0.010814135894179344\n",
            "0.010800521820783615\n",
            "0.010787224397063255\n",
            "0.010774234309792519\n",
            "0.010761542245745659\n",
            "0.01074914075434208\n",
            "0.010737027041614056\n",
            "0.01072519551962614\n",
            "0.010713637806475163\n",
            "0.010702342726290226\n",
            "0.010691311210393906\n",
            "0.010680532082915306\n",
            "0.010670005343854427\n",
            "0.0106597188860178\n",
            "0.010649668984115124\n",
            "0.0106398556381464\n",
            "0.010630263015627861\n",
            "0.010620898567140102\n",
            "0.010611744597554207\n",
            "0.010602806694805622\n",
            "0.010594069957733154\n",
            "0.010585537180304527\n",
            "0.010577203705906868\n",
            "0.01056906022131443\n",
            "0.010561103001236916\n",
            "0.01055333111435175\n",
            "0.010545739904046059\n",
            "0.010538322851061821\n",
            "0.010531078092753887\n",
            "0.010524001903831959\n",
            "0.010517086833715439\n",
            "0.010510331951081753\n",
            "0.010503734461963177\n",
            "0.01049728598445654\n",
            "0.01049098651856184\n",
            "0.01048483606427908\n",
            "0.010478825308382511\n",
            "0.01047295518219471\n",
            "0.01046721450984478\n",
            "0.010461611673235893\n",
            "0.010456139221787453\n",
            "0.010450787842273712\n",
            "0.010445566847920418\n",
            "0.0104404641315341\n",
            "0.010435478761792183\n",
            "0.010430606082081795\n",
            "0.010425848886370659\n",
            "0.010421203449368477\n",
            "0.010416658595204353\n",
            "0.010412219911813736\n",
            "0.010407891124486923\n",
            "0.010403654538094997\n",
            "0.010399521328508854\n",
            "0.010395482182502747\n",
            "0.010391531512141228\n",
            "0.010387679561972618\n",
            "0.010383911430835724\n",
            "0.010380227118730545\n",
            "0.01037662848830223\n",
            "0.010373124852776527\n",
            "0.01036969106644392\n",
            "0.010366336442530155\n",
            "0.010363064706325531\n",
            "0.010359866544604301\n",
            "0.010356742888689041\n",
            "0.010353687219321728\n",
            "0.010350706987082958\n",
            "0.010347791016101837\n",
            "0.01034494861960411\n",
            "0.010342164896428585\n",
            "0.010339448228478432\n",
            "0.01033679861575365\n",
            "0.010334204882383347\n",
            "0.010331670753657818\n",
            "0.010329196229577065\n",
            "0.010326781310141087\n",
            "0.010324420407414436\n",
            "0.010322114452719688\n",
            "0.010319860652089119\n",
            "0.010317659005522728\n",
            "0.010315509513020515\n",
            "0.010313405655324459\n",
            "0.01031135581433773\n",
            "0.010309353470802307\n",
            "0.010307392105460167\n",
            "0.010305479168891907\n",
            "0.010303610935807228\n",
            "0.010301783680915833\n",
            "0.01029999740421772\n",
            "0.010298256762325764\n",
            "0.010296555235981941\n",
            "0.010294895619153976\n",
            "0.0102932658046484\n",
            "0.01029167976230383\n",
            "0.01029012817889452\n",
            "0.010288618505001068\n",
            "0.01028713770210743\n",
            "0.010285690426826477\n",
            "0.01028428040444851\n",
            "0.010282899253070354\n",
            "0.010281549766659737\n",
            "0.01028023473918438\n",
            "0.01027894951403141\n",
            "0.01027769036591053\n",
            "0.010276464745402336\n",
            "0.010275264270603657\n",
            "0.010274095460772514\n",
            "0.010272949002683163\n",
            "0.010271834209561348\n",
            "0.010270741768181324\n",
            "0.01026967167854309\n",
            "0.010268627665936947\n",
            "0.010267614386975765\n",
            "0.010266615077853203\n",
            "0.010265644639730453\n",
            "0.01026469748467207\n",
            "0.010263768024742603\n",
            "0.010262859985232353\n",
            "0.010261976160109043\n",
            "0.010261109098792076\n",
            "0.010260266251862049\n",
            "0.010259442962706089\n",
            "0.010258635506033897\n",
            "0.010257847607135773\n",
            "0.010257076472043991\n",
            "0.010256326757371426\n",
            "0.010255593806505203\n",
            "0.01025487668812275\n",
            "0.01025417447090149\n",
            "0.010253489948809147\n",
            "0.010252824053168297\n",
            "0.010252170264720917\n",
            "0.010251527652144432\n",
            "0.01025090180337429\n",
            "0.010250297375023365\n",
            "0.010249704122543335\n",
            "0.010249121114611626\n",
            "0.01024855487048626\n",
            "0.010248001664876938\n",
            "0.010247455909848213\n",
            "0.010246927849948406\n",
            "0.010246409103274345\n",
            "0.010245902463793755\n",
            "0.010245414450764656\n",
            "0.010244930163025856\n",
            "0.010244459845125675\n",
            "0.01024399884045124\n",
            "0.010243548080325127\n",
            "0.010243108496069908\n",
            "0.010242676362395287\n",
            "0.010242263786494732\n",
            "0.010241852141916752\n",
            "0.010241450741887093\n",
            "0.010241059586405754\n",
            "0.010240677744150162\n",
            "0.010240303352475166\n",
            "0.010239941999316216\n",
            "0.010239586234092712\n",
            "0.010239237919449806\n",
            "0.010238897986710072\n",
            "0.010238568298518658\n",
            "0.010238241404294968\n",
            "0.010237926617264748\n",
            "0.0102376164868474\n",
            "0.01023731380701065\n",
            "0.010237021371722221\n",
            "0.01023673266172409\n",
            "0.010236449539661407\n",
            "0.010236172005534172\n",
            "0.010235904715955257\n",
            "0.010235639289021492\n",
            "0.010235386900603771\n",
            "0.010235133580863476\n",
            "0.010234888643026352\n",
            "0.010234648361802101\n",
            "0.010234417393803596\n",
            "0.010234188288450241\n",
            "0.010233962908387184\n",
            "0.010233748704195023\n",
            "0.010233537293970585\n",
            "0.010233324021100998\n",
            "0.01023312471807003\n",
            "0.010232926346361637\n",
            "0.010232728905975819\n",
            "0.010232541710138321\n",
            "0.010232355445623398\n",
            "0.010232171043753624\n",
            "0.010231999680399895\n",
            "0.010231822729110718\n",
            "0.010231656953692436\n",
            "0.01023149024695158\n",
            "0.010231330059468746\n",
            "0.010231174528598785\n",
            "0.010231022723019123\n",
            "0.010230869986116886\n",
            "0.01023072563111782\n",
            "0.01023058034479618\n",
            "0.01023043878376484\n",
            "0.010230302810668945\n",
            "0.01023017056286335\n",
            "0.010230038315057755\n",
            "0.010229912586510181\n",
            "0.010229790583252907\n",
            "0.010229667648673058\n",
            "0.010229552164673805\n",
            "0.01022943202406168\n",
            "0.010229318402707577\n",
            "0.010229209437966347\n",
            "0.010229097679257393\n",
            "0.01022899616509676\n",
            "0.010228891856968403\n",
            "0.010228792205452919\n",
            "0.01022869162261486\n",
            "0.010228598490357399\n",
            "0.010228501632809639\n",
            "0.010228410363197327\n",
            "0.010228320024907589\n",
            "0.010228232480585575\n",
            "0.010228145867586136\n",
            "0.01022806204855442\n",
            "0.010227982886135578\n",
            "0.010227899067103863\n",
            "0.010227825492620468\n",
            "0.0102277472615242\n",
            "0.010227671824395657\n",
            "0.01022760197520256\n",
            "0.01022752933204174\n",
            "0.010227462276816368\n",
            "0.010227394290268421\n",
            "0.010227324441075325\n",
            "0.010227261111140251\n",
            "0.010227196849882603\n",
            "0.010227138176560402\n",
            "0.010227078571915627\n",
            "0.010227018967270851\n",
            "0.010226963087916374\n",
            "0.010226902551949024\n",
            "0.010226849466562271\n",
            "0.010226796381175518\n",
            "0.010226743295788765\n",
            "0.01022669393569231\n",
            "0.010226640850305557\n",
            "0.010226592421531677\n",
            "0.010226546786725521\n",
            "0.010226497426629066\n",
            "0.010226455517113209\n",
            "0.010226408019661903\n",
            "0.01022636704146862\n",
            "0.010226322337985039\n",
            "0.010226279497146606\n",
            "0.010226240381598473\n",
            "0.01022619940340519\n",
            "0.010226162150502205\n",
            "0.01022612489759922\n",
            "0.01022608857601881\n",
            "0.0102260522544384\n",
            "0.010226019658148289\n",
            "0.01022598147392273\n",
            "0.010225951671600342\n",
            "0.010225916281342506\n",
            "0.01022588275372982\n",
            "0.010225852951407433\n",
            "0.010225821286439896\n",
            "0.010225790552794933\n",
            "0.01022576168179512\n",
            "0.010225734673440456\n",
            "0.010225706733763218\n",
            "0.010225677862763405\n",
            "0.010225648060441017\n",
            "0.010225625708699226\n",
            "0.010225599631667137\n",
            "0.010225573554635048\n",
            "0.010225553065538406\n",
            "0.010225526988506317\n",
            "0.010225502774119377\n",
            "0.010225480422377586\n",
            "0.010225458070635796\n",
            "0.01022543665021658\n",
            "0.010225417092442513\n",
            "0.010225394740700722\n",
            "0.010225377045571804\n",
            "0.010225357487797737\n",
            "0.010225338861346245\n",
            "0.010225319303572178\n",
            "0.01022530160844326\n",
            "0.010225283913314342\n",
            "0.010225263424217701\n",
            "0.010225248523056507\n",
            "0.01022523082792759\n",
            "0.010225212201476097\n",
            "0.010225200094282627\n",
            "0.010225183330476284\n",
            "0.010225167497992516\n",
            "0.010225154459476471\n",
            "0.010225138626992702\n",
            "0.010225125588476658\n",
            "0.01022510789334774\n",
            "0.010225096717476845\n",
            "0.010225086472928524\n",
            "0.01022507343441248\n",
            "0.01022505946457386\n",
            "0.010225044563412666\n",
            "0.010225032456219196\n",
            "0.010225022211670876\n",
            "0.01022501103579998\n",
            "0.010224996134638786\n",
            "0.010224989615380764\n",
            "0.01022497657686472\n",
            "0.010224966332316399\n",
            "0.010224958881735802\n",
            "0.010224948637187481\n",
            "0.010224937461316586\n",
            "0.01022492628544569\n",
            "0.010224916972219944\n",
            "0.010224907658994198\n",
            "0.010224899277091026\n",
            "0.01022489182651043\n",
            "0.010224885307252407\n",
            "0.010224875062704086\n",
            "0.010224866680800915\n",
            "0.010224858298897743\n",
            "0.010224848054349422\n",
            "0.010224847123026848\n",
            "0.010224836878478527\n",
            "0.010224832221865654\n",
            "0.010224821977317333\n",
            "0.01022481732070446\n",
            "0.010224808007478714\n",
            "0.010224803350865841\n",
            "0.010224798694252968\n",
            "0.010224788449704647\n",
            "0.010224785655736923\n",
            "0.010224778205156326\n",
            "0.010224773548543453\n",
            "0.010224767029285431\n",
            "0.010224764235317707\n",
            "0.010224754922091961\n",
            "0.010224749334156513\n",
            "0.010224745608866215\n",
            "0.010224737226963043\n",
            "0.010224736295640469\n",
            "0.010224727913737297\n",
            "0.010224726051092148\n",
            "0.010224721394479275\n",
            "0.010224713943898678\n",
            "0.010224711149930954\n",
            "0.010224705561995506\n",
            "0.010224700905382633\n",
            "0.010224699974060059\n",
            "0.010224697180092335\n",
            "0.010224690660834312\n",
            "0.010224685072898865\n",
            "0.010224685072898865\n",
            "0.010224679484963417\n",
            "0.010224675759673119\n",
            "0.010224671103060246\n",
            "0.01022467203438282\n",
            "0.010224670171737671\n",
            "0.010224664583802223\n",
            "0.010224657133221626\n",
            "0.010224655270576477\n",
            "0.010224656201899052\n",
            "0.010224651545286179\n",
            "0.010224645957350731\n",
            "0.010224645957350731\n",
            "0.010224644094705582\n",
            "0.010224644094705582\n",
            "0.010224633850157261\n",
            "0.010224633850157261\n",
            "0.010224631987512112\n",
            "0.010224631056189537\n",
            "0.01022462546825409\n",
            "0.01022462546825409\n",
            "0.010224622674286366\n",
            "0.010224618948996067\n",
            "0.010224617086350918\n",
            "0.010224615223705769\n",
            "0.010224615223705769\n",
            "0.010224610567092896\n",
            "0.010224612429738045\n",
            "0.010224606841802597\n",
            "0.010224604979157448\n",
            "0.010224604979157448\n",
            "0.010224604979157448\n",
            "0.01022460125386715\n",
            "0.010224597528576851\n",
            "0.010224597528576851\n",
            "0.010224596597254276\n",
            "0.010224593803286552\n",
            "0.010224591940641403\n",
            "0.010224590077996254\n",
            "0.01022458914667368\n",
            "0.010224586352705956\n",
            "0.01022458728402853\n",
            "0.010224584490060806\n",
            "0.010224582627415657\n",
            "0.010224578902125359\n",
            "0.010224578902125359\n",
            "0.010224579833447933\n",
            "0.010224578902125359\n",
            "0.010224577970802784\n",
            "0.01022457517683506\n",
            "0.010224572382867336\n",
            "0.010224576108157635\n",
            "0.010224569588899612\n",
            "0.010224568657577038\n",
            "0.010224571451544762\n",
            "0.010224567726254463\n",
            "0.010224567726254463\n",
            "0.010224567726254463\n",
            "0.010224566794931889\n",
            "0.01022456493228674\n",
            "0.010224564000964165\n",
            "0.010224564000964165\n",
            "0.01022456493228674\n",
            "0.010224562138319016\n",
            "0.010224560275673866\n",
            "0.010224560275673866\n",
            "0.010224555619060993\n",
            "0.010224556550383568\n",
            "0.010224556550383568\n",
            "0.010224557481706142\n",
            "0.010224555619060993\n",
            "0.010224555619060993\n",
            "0.010224556550383568\n",
            "0.010224555619060993\n",
            "0.010224553756415844\n",
            "0.010224551893770695\n",
            "0.010224553756415844\n",
            "0.01022455282509327\n",
            "0.010224550031125546\n",
            "0.010224549099802971\n",
            "0.010224547237157822\n",
            "0.010224549099802971\n",
            "0.010224548168480396\n",
            "0.010224548168480396\n",
            "0.010224546305835247\n",
            "0.010224549099802971\n",
            "0.010224547237157822\n",
            "0.010224545374512672\n",
            "0.010224544443190098\n",
            "0.010224541649222374\n",
            "0.010224545374512672\n",
            "0.010224545374512672\n",
            "0.010224543511867523\n",
            "0.010224543511867523\n",
            "0.010224544443190098\n",
            "0.010224542580544949\n",
            "0.010224541649222374\n",
            "0.010224543511867523\n",
            "0.0102245407178998\n",
            "0.010224541649222374\n",
            "0.0102245407178998\n",
            "0.010224539786577225\n",
            "0.010224542580544949\n",
            "0.010224537923932076\n",
            "0.010224537923932076\n",
            "0.010224537923932076\n",
            "0.01022453885525465\n",
            "0.010224537923932076\n",
            "0.010224537923932076\n",
            "0.0102245407178998\n",
            "0.010224539786577225\n",
            "0.01022453885525465\n",
            "0.010224534198641777\n",
            "0.010224531404674053\n",
            "0.010224536992609501\n",
            "0.010224535129964352\n",
            "0.010224539786577225\n",
            "0.010224536061286926\n",
            "0.010224535129964352\n",
            "0.010224532335996628\n",
            "0.010224536061286926\n",
            "0.010224536992609501\n",
            "0.010224535129964352\n",
            "0.010224532335996628\n",
            "0.010224534198641777\n",
            "0.010224532335996628\n",
            "0.010224534198641777\n",
            "0.010224532335996628\n",
            "0.010224533267319202\n",
            "0.010224530473351479\n",
            "0.010224532335996628\n",
            "0.010224534198641777\n",
            "0.010224532335996628\n",
            "0.010224530473351479\n",
            "0.010224534198641777\n",
            "0.010224531404674053\n",
            "0.01022452861070633\n",
            "0.010224533267319202\n",
            "0.010224533267319202\n",
            "0.010224530473351479\n",
            "0.010224531404674053\n",
            "0.010224530473351479\n",
            "0.010224533267319202\n",
            "0.01022452674806118\n",
            "0.010224532335996628\n",
            "0.01022452861070633\n",
            "0.010224530473351479\n",
            "0.010224530473351479\n",
            "0.010224530473351479\n",
            "0.010224530473351479\n",
            "0.010224531404674053\n",
            "0.010224530473351479\n",
            "0.01022452861070633\n",
            "0.010224530473351479\n",
            "0.010224529542028904\n",
            "0.010224529542028904\n",
            "0.01022452861070633\n",
            "0.01022452861070633\n",
            "0.010224531404674053\n",
            "0.010224530473351479\n",
            "0.010224527679383755\n",
            "0.010224529542028904\n",
            "0.010224531404674053\n",
            "0.010224529542028904\n",
            "0.010224530473351479\n",
            "0.010224529542028904\n",
            "0.010224530473351479\n",
            "0.010224527679383755\n",
            "0.01022452861070633\n",
            "0.010224529542028904\n",
            "0.010224530473351479\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224529542028904\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.010224532335996628\n",
            "0.010224529542028904\n",
            "0.01022452861070633\n",
            "0.010224527679383755\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.01022452861070633\n",
            "0.010224525816738605\n",
            "0.010224522091448307\n",
            "0.010224525816738605\n",
            "0.010224529542028904\n",
            "0.01022452674806118\n",
            "0.010224530473351479\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.010224525816738605\n",
            "0.010224524885416031\n",
            "0.010224530473351479\n",
            "0.010224524885416031\n",
            "0.010224529542028904\n",
            "0.010224529542028904\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224529542028904\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224523954093456\n",
            "0.010224527679383755\n",
            "0.010224527679383755\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.01022452861070633\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224529542028904\n",
            "0.010224523954093456\n",
            "0.010224525816738605\n",
            "0.010224529542028904\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.01022452861070633\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.01022452861070633\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224523954093456\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.010224523022770882\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.010224522091448307\n",
            "0.010224524885416031\n",
            "0.010224527679383755\n",
            "0.010224527679383755\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224524885416031\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224523022770882\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.010224524885416031\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224524885416031\n",
            "0.010224527679383755\n",
            "0.010224527679383755\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.01022452861070633\n",
            "0.01022452674806118\n",
            "0.010224522091448307\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.010224524885416031\n",
            "0.010224523954093456\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224523954093456\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224524885416031\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224520228803158\n",
            "0.010224523022770882\n",
            "0.010224523954093456\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.010224523954093456\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.010224524885416031\n",
            "0.010224523954093456\n",
            "0.010224522091448307\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.010224524885416031\n",
            "0.010224527679383755\n",
            "0.010224525816738605\n",
            "0.010224523022770882\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.010224521160125732\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.010224523022770882\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.01022452861070633\n",
            "0.01022452674806118\n",
            "0.010224524885416031\n",
            "0.01022452861070633\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224527679383755\n",
            "0.010224525816738605\n",
            "0.010224527679383755\n",
            "0.01022452861070633\n",
            "0.010224527679383755\n",
            "0.010224525816738605\n",
            "0.010224522091448307\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.010224523022770882\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.010224524885416031\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224523954093456\n",
            "0.010224525816738605\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.01022452674806118\n",
            "0.010224523954093456\n",
            "0.010224527679383755\n",
            "0.01022452674806118\n",
            "0.010224527679383755\n",
            "0.010224527679383755\n",
            "0.010224524885416031\n",
            "0.010224524885416031\n",
            "0.010224525816738605\n",
            "0.010224524885416031\n",
            "0.01022452674806118\n",
            "0.010224525816738605\n",
            "0.010224524885416031\n",
            "0.010224523954093456\n",
            "0.01022452674806118\n",
            "0.010224523022770882\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "0.010224525816738605\n",
            "OrderedDict([('neuron.weight', tensor([[2.0206]])), ('neuron.bias', tensor([0.9783]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmBGVB3MOrqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neuron = torch.nn.Linear(1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh76SkBhRoWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "from .unet_parts import *\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}